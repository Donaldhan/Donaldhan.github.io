---
layout: page
title: Hbase1.2.1 HA环境搭建
subtitle: Hbase1.2.1 HA环境搭建
date: 2020-01-29 22:45:19
author: donaldhan
catalog: true
category: BigData
categories:
    - BigData
tags:
    - Hbase
---

# 引言

HBase是一个分布式存储、数据库引擎，可以支持千万的QPS、PB级别的存储，这些都已经在生产环境验证，并且在广大的公司已经验证。在最近的一些版本中，引入了OffHeap降低gc影响，优化链路延迟，提供Replica等可以满足在线的需求。引入MOB，可以存储10M左右的对象，完全适应了对象存储。另外由于自身的并发能力、存储能力，可以说是具有最为竞争力的引擎。

# 目录
* [使用场景](#使用场景)
* [环境搭建](#环境搭建)
* [DDL&DML](#DDL&DML)
* [附](#附)

# 使用场景
当前主要的应用常见如下：
* 对象存储：我们知道不少的头条类、新闻类的的新闻、网页、图片存储在HBase之中，一些病毒公司的病毒库也是存储在HBase之中
* 时序数据：HBase之上有OpenTSDB模块，可以满足时序类场景的需求
* 推荐画像：特别是用户的画像，是一个比较大的稀疏矩阵，蚂蚁的风控就是构建在HBase之上
* 时空数据：主要是轨迹、气象网格之类，滴滴打车的轨迹数据主要存在HBase之中，另外在技术所有大一点的数据量的车联网企业，数据都是存在HBase之中
* CubeDB OLAP：Kylin一个cube分析工具，底层的数据就是存储在HBase之中，不少客户自己基于离线计算构建cube存储在hbase之中，满足在线报表查询的需求
* 消息/订单：在电信领域、银行领域，不少的订单查询底层的存储，另外不少通信、消息同步的应用构建在HBase之上
* Feeds流：典型的应用就是xx朋友圈类似的应用
* NewSQL：之上有Phoenix的插件，可以满足二级索引、SQL的需求，对接传统数据需要SQL非事务的需求

 
更多参考，[Hbase和Hive的特点与应用场景][], [浅谈Hive和HBase有哪些区别与联系及适用场景][]。
 
[Hbase和Hive的特点与应用场景]:https://www.jianshu.com/p/290a13b9b85c "Hbase和Hive的特点与应用场景"


[浅谈Hive和HBase有哪些区别与联系及适用场景]:https://www.jianshu.com/p/ba9171784b65 "浅谈Hive和HBase有哪些区别与联系及适用场景"


# 环境搭建
由于HBASE是基于HDFS的，在我们搭建HBASE之前，需要先把HADOOP集群搭建处理，
具体参考[Hadoop2.7.1 HA环境搭建（hdfs）][], 包括集群的规划，及软件环境；

[Hadoop2.7.1 HA环境搭建（hdfs）]:https://donaldhan.github.io/hadoop/2019/01/13/Hadoop2.7.1-HA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-hdfs.html "Hadoop2.7.1 HA环境搭建（hdfs）"


这边文章所有的配置都是基于上面这篇文章，我们用的hbase版本号是hbase-1.2.1
首先将hbase二进制包放到三台机器，并解压 */bdp/hbase*，hbase在三台机上的规划如下：

```
nameNode HMaster
secondlyNameNode HMaster HRegionServer
resourceManager	HRegionServer
```

下面我们开始搭建环境：

1. 解除 Linux 系统的最大进程数和最大文件打开数限制： 
```
vim /etc/security/limits.conf 
添加如下内容：
* soft noproc 32000  
* hard noproc 32000  
* soft nofile 32768  
* hard nofile 32768 
```
 
 2. 配置环境变量  
sudo vim ~/.bahsrc 或/etc/profile 
```
export JAVA_HOME=/usr/share/jdk1.8.0_191
export JRE_HOME=${JAVA_HOME}/jre
export CLASS_PATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export HADOOP_HOME=/bdp/hadoop/hadoop-2.7.1
export ZOOKEEPER_HOME=/bdp/zookeeper/zookeeper-3.4.12
export HBASE_HOME=//bdp/hbase/hbase-1.2.1
export PATH=${JAVA_HOME}/bin:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:${ZOOKEEPER_HOME}/bin:${HBASE_HOME}/bin:${PATH}
export HADOOP_MAPRED_HOME=${HADOOP_HOME}
export HADOOP_COMMON_HOME=${HADOOP_HOME}
export HADOOP_HDFS_HOME=${HADOOP_HOME}
export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP}/lib/native
export YARN_HOME=${HADOOP_HOME}
export HADOOP_OPT="-Djava.library.path=${HADOOP_HOME}/lib/native"
```
copy环境配置到其他两台机

```
donaldhan@nameNode:~$ scp /home/donaldhan/.bashrc donaldhan@secondlyNameNode:/home/donaldhan/
.bashrc    
donaldhan@nameNode:~$ scp /home/donaldhan/.bashrc donaldhan@resourceManager:/home/donaldhan/
.bashrc                                           100% 4446     4.3KB/s   00:00    
donaldhan@nameNode:~$ 
```

3. 修改$HBASE_HOME/conf/hbase-env.sh文件

添加如下内容
```
export JAVA_HOME=/usr/share/jdk1.8.0_191
export HBASE_OPTS="-Xmn150m"
#<!--jvm 年轻代大小,-Xmx，堆最大,-Xms，初始化堆大小-->  
#<!-- jvm GC策咯，当年老代使用了80%时回收内存，XX:+UseParNewGC：设置年轻代为并发回收 -XX:+UseConcMarkSweepGC：设置年老代为并发回收-->  
export SERVER_GC_OPTS="-XX:CMSInitiatingOccupancyFraction=80 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC"
# HBase不用管理自己的zookeeper实例，zookeeper集群自己管理 
export HBASE_MANAGES_ZK=false
```
scp到其他两台机

4. 修改文件hbase-site.xml，修改内容如下 
```
<configuration>  
    <property>    
           <name>hbase.rootdir</name>    
           <value>hdfs://ns/hbase</value>    
    </property>      
    <property>    
           <name>hbase.cluster.distributed</name>    
           <value>true</value>    
    </property>    
    <property>    
           <name>hbase.zookeeper.quorum</name>    
           <value>nameNode,secondlyNameNode,resourceManager</value>    
    </property>    
    <property>    
           <name>dfs.replication</name>    
           <value>3</value>    
    </property>    
     <!-- 开启web界面-->
    <property>  
        <name>hbase.master.info.port</name>  
        <value>60010</value>  
    </property> 

</configuration> 
```
scp到其他两台机

5. 修改文件regionservers，修改内容如下 

```
donaldhan@nameNode:/bdp/hbase/hbase-1.2.1/conf$ cat regionservers 
secondlyNameNode
resourceManage
```
6. 添加backup-masters文件

```
donaldhan@nameNode:/bdp/hbase/hbase-1.2.1/conf$ cat backup-masters 
secondlyNameNode
```

backup-masters每行一个主机名，代表备用master，提高可用性及健壮性。

直至HA环境搭建完毕。


# DDL&DML
## 启动HBASE
1. 首先在分布式环境中启动zk
```
zkServer.sh start
```

2. 启动hadoop集群

```
start-dfs.sh
```

3. 启动HBASE集群

```
start-hbase.sh  
```

访问 http://namenode:60010/master-status ，可以查看HBASE集群的情况。

## 简单的DDL
启动hbase shell，进入shell环境 
```
hbase shell  
```
1. 创建表 
```
create 'users','user_id','address','info'  
```
说明:表users,有三个列族user_id,address,info

2. 列出全部表 
```
list  
```
3. 表的描述 
```
describe 'users'  
```

### 简单的DML

1. 添加记录   
put ‘表名’,’行键(标识)’,’列族:字段’,’数值’   
示例： 
```
put 'users','xiaoming','info:age','24';    
put 'users','xiaoming','info:birthday','1987-06-17';    
put 'users','xiaoming','info:company','alibaba';    
put 'users','xiaoming','address:contry','china';    
put 'users','xiaoming','address:province','zhejiang';    
put 'users','xiaoming','address:city','hangzhou';    
put 'users','zhangyifei','info:birthday','1987-4-17';    
put 'users','zhangyifei','info:favorite','movie';    
put 'users','zhangyifei','info:company','alibaba';    
put 'users','zhangyifei','address:contry','china';    
put 'users','zhangyifei','address:province','guangdong';    
put 'users','zhangyifei','address:city','jieyang';    
put 'users','zhangyifei','address:town','xianqiao'; 
```

2. 获取一条记录 

* 取得一个id的所有数据 
```
get 'users','xiaoming'   
 ``` 
* 获取一个id，一个列族的所有数据 

```
get 'users','xiaoming','info'    
```
*  获取一个id，一个列族中一个列的所有数据 
```
get 'users','xiaoming','info:age'  
``` 

3. 更新记录 
```
put 'users','xiaoming','info:age' ,'29'    
get 'users','xiaoming','info:age'    
put 'users','xiaoming','info:age' ,'30'    
get 'users','xiaoming','info:age'   
```

4. 获取单元格数据的版本数据 
```
get 'users','xiaoming',{COLUMN=>'info:age',VERSIONS=>1}    
get 'users','xiaoming',{COLUMN=>'info:age',VERSIONS=>2}    
get 'users','xiaoming',{COLUMN=>'info:age',VERSIONS=>3}   
```

5. 获取单元格数据的某个版本数据 
```
get 'users','xiaoming',{COLUMN=>'info:age',TIMESTAMP=>1364874937056}  
```

6. 全表扫描 
```
scan 'users'   
```

7. 删除xiaoming值的'info:age'字段 
```
delete 'users','xiaoming','info:age'   
get 'users','xiaoming'   
```

8. 删除整行 
```
deleteall 'users','xiaoming'   
  ```
9. 统计表的行数 
```
count 'users'   
```

10. 清空表 
```
truncate 'users'   
```
 

## 关闭HBASE

1. 关闭HBASE集群

```
stop-hbase.sh  
```

2. 关闭hadoop集群

```
stop-dfs.sh
```

3. 关闭分布式环境中启动zk
```
zkServer.sh stop
```

## 附

1. 无法访问HADOOP集群

具体错误信息如下，
```
donaldhan@nameNode:/bdp/hbase/hbase-1.2.1/logs$ tail -f hbase-donaldhan-master-nameNode.log 

2020-01-29 16:56:18,846 FATAL [nameNode:16000.activeMasterManager] master.HMaster: Failed to become active master
java.net.ConnectException: Call From nameNode/192.168.5.135 to nameNode:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
        at org.apache.hadoop.ipc.Client.call(Client.java:1415)
        at org.apache.hadoop.ipc.Client.call(Client.java:1364)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
        at com.sun.proxy.$Proxy17.setSafeMode(Unknown Source)
        at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
        at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
        at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
        at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:525)
        at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:971)
        at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:424)
        at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:153)
        at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:128)
        at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:638)
        at org.apache.hadoop.hbase.master.HMaster.access$500(HMaster.java:184)
        at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1729)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
                                                                                                  
```
 *解决方式*
由于hadoop集群是高可用的，由于高可用环境没有起来，导致habse启动失败：
修改文件hbase-site.xml，的hbase.rootdir内容如下
```
    <property>    
           <name>hbase.rootdir</name>    
           <value>hdfs://ns/hbase</value>    
    </property>      
```

原始配置为：
```
    <property>    
           <name>hbase.rootdir</name>    
           <value>hdfs://nameNode:9000/hbase</value>    
    </property>      
```

2. 无法访问HBASE web监控页面 http://namenode:60010/master-status
首先查看HBase集群有没有起来，如果HBASE集群没有起来，可定无法访问；
HBASE起来之后，检查端口有没有开启。

donaldhan@nameNode:/bdp/hbase/hbase-1.2.1/bin$ netstat -ntlp
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 192.168.5.135:3888      0.0.0.0:*               LISTEN      3800/java       
tcp        0      0 192.168.5.135:8019      0.0.0.0:*               LISTEN      10578/java      
tcp        0      0 192.168.5.135:8020      0.0.0.0:*               LISTEN      9959/java       
tcp        0      0 127.0.1.1:53            0.0.0.0:*               LISTEN      -               
tcp        0      0 192.168.5.135:50070     0.0.0.0:*               LISTEN      9959/java       
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -               
tcp        0      0 0.0.0.0:50010           0.0.0.0:*               LISTEN      10105/java      
tcp        0      0 0.0.0.0:50075           0.0.0.0:*               LISTEN      10105/java      
tcp        0      0 192.168.5.135:16000     0.0.0.0:*               LISTEN      10795/java      
tcp        0      0 0.0.0.0:8480            0.0.0.0:*               LISTEN      10348/java      
tcp        0      0 0.0.0.0:50020           0.0.0.0:*               LISTEN      10105/java      
tcp        0      0 0.0.0.0:8485            0.0.0.0:*               LISTEN      10348/java      
tcp        0      0 0.0.0.0:2181            0.0.0.0:*               LISTEN      3800/java       
tcp        0      0 0.0.0.0:60010           0.0.0.0:*               LISTEN      10795/java   